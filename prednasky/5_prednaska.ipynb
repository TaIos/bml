{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Přednáška 5: Zobecněné lineární modely (GLM, Generalized Linear Models)\n",
    "\n",
    "**Obsah přednášky**\n",
    "- Motivační příklad\n",
    "- GLM - základní principy\n",
    "- logistická regrese\n",
    "- sigmoid fce, logistická fce (scipy)\n",
    "- kvantifikace chyb\n",
    "- příklad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM - trocha matematiky \n",
    "\n",
    "Označme stejně jako v případě dříve probraných **lineárních modelů** pozorovanou náhodnou veličinu $Y_t$ s realizacemi $y_1, y_2, \\ldots$. Budeme předpokládat, že má nějaké rozdělení z **exponenciální třídy distribucí**, což jak už rovněž víme, může být například normální, binomické, Poissonovo nebo gama. Stejně jako u lineárních modelů budeme uvažovat **vysvětlující (nezávislou) proměnnou - regresor** $X_t$ s realizacemi $x_1, x_2,\\ldots$ a dále **vektor regresních koeficientů** $\\beta$ o stejném rozměru jako $X$.\n",
    "\n",
    "Vzpomeňme na lineární regresi, kde $y_t = \\beta^\\intercal x_t + \\varepsilon_t$.\n",
    "\n",
    "> **Zobecněné lineární modely** jsou modely ve tvaru\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[Y_t] = g^{-1}(\\beta^\\intercal X_t),\n",
    "$$\n",
    "\n",
    "> kde $\\mathbb{E}[Y_t]$ je střední hodnota $Y_t$, $\\beta^\\intercal X_t$ je lineární prediktor stejně jako v lineární regresi a $g$ je linková (spojovací) funkce.\n",
    "\n",
    "Ještě lépe pochopitelné to bude po zmínce, že střední hodnota se někdy nazývá *očekávanou hodnotou*, angl. expected value nebo expectation.\n",
    "\n",
    "Z rovnice výše plyne, že\n",
    "$$\n",
    "\\beta^\\intercal X_t = g(\\mathbb{E}[Y_t]),\n",
    "$$\n",
    "\n",
    "tedy že linková funkce spojuje lineární prediktor $\\beta^\\intercal X_t$ se střední (očekávanou) hodnotou $Y_t$.\n",
    "\n",
    "**Úkol:**\n",
    "- lineární regrese je rovněž zobecněným lineárním modelem. Jak v tom případě vypadají funkce $g$ a $g^{-1}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Příklady linkových funkcí $g$\n",
    "#### Dichotomická veličina $Y \\sim \\{0, 1\\}$\n",
    "Pro binární (dichotomickou) veličinu s *Bernoulliho rozdělením* s pravděpodobností $p$ výhodou používáme funkci [logit](https://en.wikipedia.org/wiki/Logit):\n",
    "\n",
    "$$\n",
    "\\mathit{logit}(p) = \\log\\left(\\frac{p}{1-p}\\right).\n",
    "$$\n",
    "\n",
    "Její inverze se nazývá [logistickou funkcí](https://en.wikipedia.org/wiki/Logistic_function), též sigmoid funkcí (to je ale spíše [celá množina funkcí](https://en.wikipedia.org/wiki/Logit)). Logistická funkce má tvar\n",
    "\n",
    "$$\n",
    "\\mathit{logit}^{-1}(z) = \\sigma(z) = \\frac{e^z}{1+e^z} = \\frac{1}{1+e^{-z}}.\n",
    "$$\n",
    "\n",
    "Za argument $z$ dosazujeme $\\beta^\\intercal x_t$, čímž dostáváme **logistickou regresi**. Grafy obou funkcí ukazují obrázky.\n",
    "\n",
    "![logit](img/logit_expit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poissonovská veličina $Y_t \\sim \\textit{Poisson}(\\cdot)$\n",
    "Poissonovo rozdělení používáme pro popis počtu jevů nastalých v určitém místě nebo časovém okamžiku, např. počet částic dopadnuvších na detektor za daný časový okamžik, počet zákazníků kontaktujících call centrum v závislosti na velikosti lokality, počet úmrtí v dané věkové kategorii za definovaný časový úsek aj. Jelikož potřebujeme lineární prediktor $\\beta^\\intercal X_t$ zobrazit nějakým způsobem na množinu kladných čísel, můžeme s výhodou využít logaritmus. Inverzní zobrazení - počet realizací - nám pak dodá exponenciální funkce.\n",
    "\n",
    "Jinými slovy: **Poissonovská regrese** pracuje s modelem\n",
    "\n",
    "$$\n",
    "\\log \\mathbb{E}[Y] = \\beta^\\intercal X, \\qquad \\text{respektive} \\qquad \\mathbb{E}[Y] = e^{\\beta^\\intercal X}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistická regrese\n",
    "\n",
    "Logistický regresní model je určen pro popis dichotomické veličiny\n",
    "\n",
    "$$\n",
    "Y_t = \n",
    "\\begin{cases} \n",
    "0 \\quad \\text{s pravděpodobností $p_t$}, \\\\ \n",
    "1 \\quad \\text{s pravděpodobností $1 - p_t$}.\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Z dřívějška víme, že vhodnou distribucí pro $Y_t$ je distribuce **Bernoulliho** (též alternativní) s pravděpodobností $p_t$ jako svým parametrem,\n",
    "\n",
    "$$\n",
    "Y_t \\sim \\textit{Bernoulli}(p_t)\n",
    "$$\n",
    "a **se střední hodnotou** $\\mathbb{E}[Y_t] = p_t$.\n",
    "\n",
    "Máme-li k dispozici nezávislou vysvětlující proměnnou (regresor) $X_t$, pokusíme se najít vhodné $\\beta$ a $Y_t$ s nimi vhodně provázat.\n",
    "\n",
    "Připomeňme ještě, že pravděpodobnostní funkce Bernoulliho rozdělení je\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f(y_t|p_t) &= p_t^{y_t} (1-p_t)^{1-y_t} \\\\\n",
    "           &= f(y_t|x_t, \\beta),\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "kde druhý řádek jsme si doplnili pro pořádek, důvod se ukáže vzápětí :-)\n",
    "\n",
    "Z teorie GLM výše víme, že potřebujeme vhodnou linkovou funkci, která prováže *lineární prediktor* $\\beta^\\intercal X_t$ s $Y_t$, respektive jeho střední (očekávanou) hodnotou,\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[Y_t|X_t, \\beta] = g^{-1}(\\beta^\\intercal X_t).\n",
    "$$\n",
    "\n",
    "A dokonce už také víme, že vhodnou volbou pro $g$ je funkce $\\textit{logit}$, a tedy\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "g(\\mathbb{E}[Y_t|p_t]) \n",
    "&= g(\\mathbb{E}[Y_t|X_t, \\beta]) \\\\\n",
    "&= g(p_t) \\\\\n",
    "&= \\textit{logit}(p_t) \\\\\n",
    "&= \\log \\frac{p_t}{1-p_t}\n",
    "= \\beta^\\intercal X_t. \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Analogicky tedy inverzí\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[Y_t|X_t, \\beta]\n",
    "&= p_t \\\\\n",
    "&= \\textit{logit}^{-1}(\\beta^\\intercal X_t) \\\\\n",
    "&= \\sigma(\\beta^\\intercal X_t) \\\\\n",
    "&= \\frac{1}{1+e^{-\\beta^\\intercal X_t}}.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesovský odhad logistického regresního modelu\n",
    "\n",
    "Bayesovský odhad $\\beta$ není triviální, neboť aposteriorní distribuce\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\pi(\\beta|x_{0:t}, y_{0:t}) \n",
    "&\\propto f(y_t|x_t, \\beta) \\times \\pi(\\beta|x_{0:t-1}, y_{0:t-1}) \\\\\n",
    "&\\propto p_t^{y_t} (1-p_t)^{1-y_t}) \\times \\pi(\\beta|x_{0:t-1}, y_{0:t-1}) \\\\\n",
    "&\\propto [\\sigma(\\beta^\\intercal x_t)]^{y_t}\n",
    "[1-\\sigma(\\beta^\\intercal x_t)]^{1-y_t} \\times \\pi(\\beta|x_{0:t-1}, y_{0:t-1})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "není analyticky dostupná pro žádnou rozumnou volbu apriorna. Možností, jak k problému přistoupit je povícero - buď odhad pomocí metod Monte Carlo, nebo variačními metodami, nebo aproximativně laplaceovskou aproximací. My si vybereme tu poslední variantu.\n",
    "\n",
    "Zvolíme si jako apriorno vícerozměrnou normální distribuci\n",
    "\n",
    "$$\n",
    "\\beta|X_{0:t-1}, Y_{0:t-1} \\sim \\mathcal{N}(\\widehat{\\beta}_{t-1}, \\Sigma_{t-1}). \n",
    "$$\n",
    "\n",
    "Aposteriorní distribuci pořešíme aproximativně ve dvou krocích:\n",
    "1. Najdeme maximum aposteriorní distribuce uvedené výše. Tím dostaneme MAP (maximum a posteriori) odhad.\n",
    "2. Do tohoto maxima umístíme střední hodnotu normální hustoty a najdeme pro ni odpovídající vhodnou kovarianci.\n",
    "\n",
    "**Úkoly:**\n",
    "- obecně: jakým způsobem hledáme maximum funkce?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Intermezzo: Newtonova metoda**\n",
    ">\n",
    "> Je-li dána dostatečně \"rozumná\" funkce $g$ - zejm. spojitá s existující derivací a monotónní v určeném intervalu, pak pro nalezení bodu $x$ v němž platí  $g(x)=0$ lze použít Newtonovu metodu. Odstartujeme-li z \"rozumného\" bodu $x_0$, najdeme nový bod $x_1$ na průsečíku tečny v $g(x_0)$ s osou $x$ a takto postupně iterujeme až do dosažení požadované přesnosti nebo počtu iterací. Ve třech krocích nám nalezení $x_1$ vysvětlí následující obrázek.\n",
    "![Newtonova metoda](img/Newton2.png)\n",
    "\n",
    "**Úkoly:**\n",
    "- Už víme, že budeme hledat maximum aposteriorní distribuce $\\pi(\\beta|x_{0:t}, y_{0:t})$. Co bude analogií k funkci $g$ v \"Intermezzu\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hledání střední hodnoty aproximující normální distribuce\n",
    "Už tedy víme, že budeme \"newtonovsky\" hledat maximum $\\widehat{\\beta}_t$. Můžeme to dělat i jen jednokrokovým Newtonem, kde za počáteční hodnotu (analogické k $x_0$) vybereme minulý odhad $\\widehat{\\beta}_{t-1}$,\n",
    "\n",
    "$$\n",
    "\\widehat{\\beta}_t = \\widehat{\\beta}_{t-1} - [l''(\\widehat{\\beta}_{t-1})]^{-1} l'(\\widehat{\\beta}_{t-1}),\n",
    "$$\n",
    "\n",
    "kde\n",
    "\n",
    "$$\n",
    "l(\\widehat{\\beta}_{t-1}) = \\log \\pi(\\beta|x_{0:t}, y_{0:t}) \n",
    "$$\n",
    "\n",
    "je logaritmus aposteriorní hustoty v bodě $\\widehat{\\beta}_{t-1}$. Pro úplnost dodejme, že\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "l'(\\widehat{\\beta}_{t-1}) \n",
    "&= x_t\\left(y_t - \\sigma(\\widehat{\\beta}_{t-1}x_t)\\right),\\\\\n",
    "l''(\\widehat{\\beta}_{t-1})\n",
    "&= -\\Sigma_{t-1} - x^\\intercal R x \\qquad\\text{kde}\\quad\n",
    "R = \\text{diag} \\left[\n",
    "\\sigma\\left(\\widehat\\beta_{t-1}^{\\intercal}x_t \\right)\n",
    "\\left(1-\\sigma\\left(\\widehat\\beta_{t-1}^{\\intercal}x_t\\right)\\right)\n",
    "\\right].\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Tady se to trochu zkomplikovalo, neboť jsme museli dělat derivace ve více rozměrech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hledání kovariance aproximující normální hustoty\n",
    "Pokud jsme nalezli MAP odhad, nafitujeme normální distribuci s kovariancí\n",
    "\n",
    "$$\n",
    "\\Sigma_t = -[l''(\\widehat{\\beta}_{t-1})]^{-1}.\n",
    "$$\n",
    "\n",
    "To již máme spočteno z předchozího kroku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmus\n",
    "\n",
    "Algoritmus tedy vypadá následovně:\n",
    "\n",
    "**Inicializace**\n",
    "- Nastavíme vhodné počáteční hyperparametry apriorního normálního rozdělení $\\widehat\\beta_{t-1}, \\Sigma_{t-1}$.\n",
    "\n",
    "**Online modelování**\n",
    "1. Získáme nová měření $y_t$ a regresor $x_t$.\n",
    "2. Napočítáme MAP odhad $\\widehat{\\beta}_t$.\n",
    "3. Napočítáme aproximativní kovarianci odhadu $\\Sigma_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predikce\n",
    "\n",
    "Bayesovská predikce běží přes prediktivní distribuci, která ovšem rovněž není analyticky dostupná. Místo toho můžeme využít laplaceovskou aproximaci\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f(y'|x', x_{0:t}, y_{0:t}) \n",
    "&= \\int f(y'|x', x_{0:t}, y_{0:t}, \\beta) \\pi(\\beta|x_{0:t}, y_{0:t}) d\\beta  \\\\\n",
    "&\\approx\n",
    "(2\\pi)^{\\frac{n}{2}} \\left[\\det l''(\\widehat{\\beta}_t)\\right]^{-\\frac{1}{2}} f(y'|x', \\beta)\\ \\pi(\\beta|x_{0:t},y_{0:t}),\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "kde dosadíme $\\beta = \\widehat{\\beta}_t$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
